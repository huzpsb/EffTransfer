{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f75bdd14e82051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from PIL.Image import Resampling\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from lion_pytorch import Lion\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7901d547662c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "mat_data = scipy.io.loadmat('imagelabels.mat')\n",
    "image_data = mat_data['labels']\n",
    "image_array = np.array(image_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7598f56bcaf7fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256\n",
    "\n",
    "\n",
    "def resize_and_crop(img):\n",
    "    x, y = img.size\n",
    "\n",
    "    if x > y:\n",
    "        scale = size / y\n",
    "        new_x = int(x * scale)\n",
    "        img_resized = img.resize((new_x, size), Resampling.LANCZOS)\n",
    "\n",
    "        crop_margin = int(((size / 2) * (x - y)) / y)\n",
    "        left = crop_margin\n",
    "        right = left + size\n",
    "        img_cropped = img_resized.crop((left, 0, right, size))\n",
    "\n",
    "    elif y > x:\n",
    "        scale = size / x\n",
    "        new_y = int(y * scale)\n",
    "        img_resized = img.resize((size, new_y), Resampling.LANCZOS)\n",
    "\n",
    "        crop_margin = int(((size / 2) * (y - x)) / x)\n",
    "        top = crop_margin\n",
    "        bottom = crop_margin + size\n",
    "        img_cropped = img_resized.crop((0, top, size, bottom))\n",
    "\n",
    "    else:\n",
    "        img_cropped = img.resize((size, size), Resampling.LANCZOS)\n",
    "\n",
    "    return img_cropped.convert(\"RGB\")\n",
    "\n",
    "def resize_and_crop2(img):\n",
    "    x, y = img.size\n",
    "\n",
    "    if x > y:\n",
    "        scale = size / y\n",
    "        new_x = int(x * scale)\n",
    "        img_resized = img.resize((new_x, size), Resampling.LANCZOS)\n",
    "\n",
    "        crop_margin = int(((size / 1.1) * (x - y)) / y)\n",
    "        left = crop_margin\n",
    "        right = left + size\n",
    "        img_cropped = img_resized.crop((left, 0, right, size))\n",
    "\n",
    "    elif y > x:\n",
    "        scale = size / x\n",
    "        new_y = int(y * scale)\n",
    "        img_resized = img.resize((size, new_y), Resampling.LANCZOS)\n",
    "\n",
    "        crop_margin = int(((size / 1.1) * (y - x)) / x)\n",
    "        top = crop_margin\n",
    "        bottom = crop_margin + size\n",
    "        img_cropped = img_resized.crop((0, top, size, bottom))\n",
    "\n",
    "    else:\n",
    "        img_cropped = img.resize((size, size), Resampling.LANCZOS)\n",
    "\n",
    "    return img_cropped.convert(\"RGB\")\n",
    "\n",
    "\n",
    "class Dataset102f:\n",
    "    def __init__(self):\n",
    "        ds = []\n",
    "        self.classes = 102\n",
    "\n",
    "        self.one_hot_dict = {}\n",
    "        for i in range(102):\n",
    "            one_hot_np = np.zeros(102)\n",
    "            one_hot_np[i] = 1\n",
    "            one_hot_tensor = torch.from_numpy(one_hot_np).float().to(device)\n",
    "            self.one_hot_dict[i] = one_hot_tensor\n",
    "\n",
    "        for i in range(8189):\n",
    "            offset = i + 1\n",
    "            clazz = image_array[i]\n",
    "            img = Image.open(\"102f/image_\" + \"{:05d}\".format(offset) + \".jpg\")\n",
    "\n",
    "            img1 = resize_and_crop(img)\n",
    "            np_img = np.array(img1).astype(np.float32) / 255\n",
    "            tensor_img = torch.from_numpy(np_img).float().permute(2, 0, 1).to(device)\n",
    "            ds.append((tensor_img, self.one_hot_dict[clazz - 1]))\n",
    "\n",
    "            img2 = resize_and_crop2(img)\n",
    "            np_img = np.array(img2).astype(np.float32) / 255\n",
    "            tensor_img = torch.from_numpy(np_img).float().permute(2, 0, 1).to(device)\n",
    "            ds.append((tensor_img, self.one_hot_dict[clazz - 1]))\n",
    "\n",
    "        np.random.shuffle(ds)\n",
    "        split_point = int(len(ds) * 0.8)\n",
    "        self.train_data = ds[:split_point]\n",
    "        self.test_data = ds[split_point:]\n",
    "\n",
    "\n",
    "dataset = Dataset102f()\n",
    "\n",
    "tds_train = TensorDataset(torch.stack([x[0] for x in dataset.train_data]),\n",
    "                          torch.stack([x[1] for x in dataset.train_data]), )\n",
    "tdsl_train = DataLoader(tds_train, batch_size=32, shuffle=True)\n",
    "\n",
    "tds_test = TensorDataset(torch.stack([x[0] for x in dataset.test_data]),\n",
    "                         torch.stack([x[1] for x in dataset.test_data]), )\n",
    "tdsl_test = DataLoader(tds_test, batch_size=32, shuffle=False)\n",
    "\n",
    "dataset.train_data = None  # free memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa803a33fb317523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "\n",
    "model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features, dataset.classes)\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Lion(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bdc5941fd0c0ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in data_loader:\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = loss_fn(outputs, y)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate statistics\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        pred_labels = torch.argmax(outputs, dim=1)\n",
    "        y_labels = torch.argmax(y, dim=1)\n",
    "        correct += (pred_labels == y_labels).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def evaluate_epoch(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            pred = model(x)\n",
    "\n",
    "            pred_labels = torch.argmax(pred, dim=1)\n",
    "            y_labels = torch.argmax(y, dim=1)\n",
    "\n",
    "            correct += (pred_labels == y_labels).sum().item()\n",
    "\n",
    "    accuracy = correct / len(data_loader.dataset)\n",
    "    return total_loss / len(data_loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f175ee1ff3fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] - Train Loss: 2.8107, Train Acc: 0.5324, Test Loss: 0.0000, Test Acc: 0.8883, \n",
      "Epoch [2] - Train Loss: 0.7345, Train Acc: 0.9028, Test Loss: 0.0000, Test Acc: 0.9365, \n",
      "Epoch [3] - Train Loss: 0.3117, Train Acc: 0.9454, Test Loss: 0.0000, Test Acc: 0.9634, \n",
      "Epoch [4] - Train Loss: 0.1842, Train Acc: 0.9677, Test Loss: 0.0000, Test Acc: 0.9722, \n",
      "Epoch [5] - Train Loss: 0.1217, Train Acc: 0.9782, Test Loss: 0.0000, Test Acc: 0.9777, \n",
      "Epoch [6] - Train Loss: 0.0953, Train Acc: 0.9820, Test Loss: 0.0000, Test Acc: 0.9805, \n",
      "Epoch [7] - Train Loss: 0.0749, Train Acc: 0.9867, Test Loss: 0.0000, Test Acc: 0.9838, \n",
      "Epoch [8] - Train Loss: 0.0618, Train Acc: 0.9890, Test Loss: 0.0000, Test Acc: 0.9866, \n",
      "Epoch [9] - Train Loss: 0.0546, Train Acc: 0.9895, Test Loss: 0.0000, Test Acc: 0.9863, \n",
      "Epoch [10] - Train Loss: 0.0458, Train Acc: 0.9913, Test Loss: 0.0000, Test Acc: 0.9850, \n",
      "Epoch [11] - Train Loss: 0.0469, Train Acc: 0.9901, Test Loss: 0.0000, Test Acc: 0.9850, \n",
      "Epoch [12] - Train Loss: 0.0403, Train Acc: 0.9915, Test Loss: 0.0000, Test Acc: 0.9863, \n",
      "Epoch [13] - Train Loss: 0.0365, Train Acc: 0.9912, Test Loss: 0.0000, Test Acc: 0.9860, \n",
      "Epoch [14] - Train Loss: 0.0338, Train Acc: 0.9921, Test Loss: 0.0000, Test Acc: 0.9869, \n",
      "Epoch [15] - Train Loss: 0.0290, Train Acc: 0.9938, Test Loss: 0.0000, Test Acc: 0.9875, \n",
      "Epoch [16] - Train Loss: 0.0289, Train Acc: 0.9937, Test Loss: 0.0000, Test Acc: 0.9860, \n",
      "Epoch [17] - Train Loss: 0.0279, Train Acc: 0.9938, Test Loss: 0.0000, Test Acc: 0.9866, \n",
      "Epoch [18] - Train Loss: 0.0278, Train Acc: 0.9929, Test Loss: 0.0000, Test Acc: 0.9866, \n",
      "Epoch [19] - Train Loss: 0.0270, Train Acc: 0.9937, Test Loss: 0.0000, Test Acc: 0.9863, \n",
      "Epoch [20] - Train Loss: 0.0251, Train Acc: 0.9936, Test Loss: 0.0000, Test Acc: 0.9872, \n",
      "Epoch [21] - Train Loss: 0.0244, Train Acc: 0.9936, Test Loss: 0.0000, Test Acc: 0.9875, \n",
      "Epoch [22] - Train Loss: 0.0232, Train Acc: 0.9944, Test Loss: 0.0000, Test Acc: 0.9860, \n",
      "Epoch [23] - Train Loss: 0.0237, Train Acc: 0.9942, Test Loss: 0.0000, Test Acc: 0.9893, \n",
      "Epoch [24] - Train Loss: 0.0223, Train Acc: 0.9940, Test Loss: 0.0000, Test Acc: 0.9890, \n",
      "Epoch [25] - Train Loss: 0.0192, Train Acc: 0.9959, Test Loss: 0.0000, Test Acc: 0.9890, \n",
      "Epoch [26] - Train Loss: 0.0240, Train Acc: 0.9932, Test Loss: 0.0000, Test Acc: 0.9878, \n",
      "Epoch [27] - Train Loss: 0.0241, Train Acc: 0.9934, Test Loss: 0.0000, Test Acc: 0.9869, \n",
      "Epoch [28] - Train Loss: 0.0183, Train Acc: 0.9945, Test Loss: 0.0000, Test Acc: 0.9884, \n",
      "Epoch [29] - Train Loss: 0.0232, Train Acc: 0.9937, Test Loss: 0.0000, Test Acc: 0.9872, \n",
      "Epoch [30] - Train Loss: 0.0203, Train Acc: 0.9943, Test Loss: 0.0000, Test Acc: 0.9881, \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    train_loss, train_acc = train_epoch(model, tdsl_train, loss_fn, optimizer)\n",
    "    test_loss, test_acc = evaluate_epoch(model, tdsl_test)\n",
    "    print(f\"Epoch [{epoch + 1}] - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, \")\n",
    "    if test_acc > 0.975:\n",
    "        torch.save(model, f\"102f_model_{epoch + 1}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
